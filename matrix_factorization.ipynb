{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import matrix_factorization as mf\n",
    "import metrics\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_random_state(random_state):\n",
    "    if type(random_state) == np.random.RandomState:\n",
    "        random = random_state\n",
    "    else:\n",
    "        random = np.random.RandomState(random_state)\n",
    "    return random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection / measurement matrices\n",
    "\n",
    "We consider sparse binary projection matrices $P$ that correspond to the adjacency matrix of a bipartite graph where each node on the left-side of the graph has exactly $s$ neighbors. We use a simple randomized construction: for each column of the adjacency matrix, set $s$ distinct entries chosen uniformly at random to $1$. Informally speaking, random graphs of this form are known to be *bipartite expanders* with high probability -- a property that we use in the theoretical analysis in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_projection(d, n, s, dtype=np.float32, random_state=None):\n",
    "    \"\"\"Sample a sparse binary projection matrix.\n",
    "    \n",
    "    Args:\n",
    "        d: int, number of rows/projection dimension\n",
    "        n: int, number of columns/input dimension\n",
    "        s: int, column sparsity of matrix\n",
    "        dtype: data type\n",
    "        random_seed: random seed\n",
    "        \n",
    "    Returns:\n",
    "        Projection matrix of type scipy.sparse.csr.csr_matrix\n",
    "    \"\"\"\n",
    "    random = _get_random_state(random_state)\n",
    "    adj = np.zeros([n, s], dtype=np.int32)\n",
    "    for i in range(n):\n",
    "        adj[i] = random.choice(d, replace=False, size=s)\n",
    "    P = sparse.lil_matrix((d, n), dtype=dtype)\n",
    "    for i in range(n):\n",
    "        for j in random.choice(d, replace=False, size=s):\n",
    "            P[j, i] = 1\n",
    "    return P.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic(W_sparsity=100, rank=10, n=2000, m=2000, d=400,\n",
    "                       P_sparsity=5, nonneg=False, noise_scale=0.1, \n",
    "                       random_state=None, dtype=np.float32, verbose=False):\n",
    "    \"\"\"Generate a synthetic low-rank + noise matrix.\n",
    "    \n",
    "    Args:\n",
    "        W_sparsity: int, column sparsity of the left factor W\n",
    "        rank: int, rank parameter\n",
    "        n: int, number of rows of the uncompressed matrix\n",
    "        m: int, number of columns\n",
    "        d: int, number of rows of the compressed matrix\n",
    "        nonneg: bool, if true, then W and H are nonnegative\n",
    "        noise_scale: float, Frobenius norm of noise matrix as fraction of norm of the noiseless matrix\n",
    "        random_seed: random seed\n",
    "        dtype: str or dtype, datatype of generated data\n",
    "        verbose: bool, whether to print parameters\n",
    "        \n",
    "    Returns:\n",
    "        dict containing generated data\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print('W_sparsity =', W_sparsity)\n",
    "        print('rank =', rank)\n",
    "        print('n =', n)\n",
    "        print('m =', m)\n",
    "        print('d =', d)\n",
    "        print('P_sparsity =', P_sparsity)\n",
    "        print('nonneg =', nonneg)\n",
    "        print('noise_scale =', noise_scale)\n",
    "    \n",
    "    random = _get_random_state(random_state)\n",
    "    W = random.randn(n, rank).astype(dtype)\n",
    "    for i in range(rank):\n",
    "        s = np.zeros(n, dtype=dtype)\n",
    "        s[random.choice(n, size=W_sparsity, replace=False)] = 1\n",
    "        W[:, i] *= s\n",
    "    \n",
    "    H = random.randn(rank, m).astype(dtype)\n",
    "    for i in range(rank):\n",
    "        H[i] /= np.linalg.norm(H[i])\n",
    "    \n",
    "    if nonneg:\n",
    "        W = np.abs(W)\n",
    "        H = np.abs(H)\n",
    "        \n",
    "    X_true = W.dot(H)\n",
    "    \n",
    "    noise = random.randn(n, m).astype(dtype)\n",
    "    noise *= noise_scale * np.linalg.norm(X_true, 'fro') / np.linalg.norm(noise, 'fro')\n",
    "    X = X_true + noise\n",
    "    \n",
    "    P = sample_projection(d, n, s=P_sparsity, random_state=random, dtype=dtype)\n",
    "    return dict(X=X, X_true=X_true, W=W, H=H, P=P, PX=P.dot(X), PW=P.dot(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_nmf_experiment(rank=10, nonneg_recovery=False, random_state=None, verbose=False, show_progress=False, **kwargs):\n",
    "    random = _get_random_state(random_state)\n",
    "    \n",
    "    # generate synthetic low-rank + noise matrix\n",
    "    data = generate_synthetic(rank=rank, nonneg=True, random_state=random, verbose=verbose, **kwargs)\n",
    "    \n",
    "    # factorize and recover\n",
    "    factors = mf.compressed_factorization(\n",
    "        data['PX'], \n",
    "        rank=rank, \n",
    "        fn=mf.nmf, \n",
    "        proj=data['P'], \n",
    "        nonneg=nonneg_recovery,\n",
    "        random_state=random,\n",
    "        show_progress=show_progress,\n",
    "        verbose=verbose)\n",
    "        \n",
    "    res = defaultdict(dict)\n",
    "    \n",
    "    # factor matching\n",
    "    What, Hhat = metrics.normalize_factors(factors['W'], factors['H'])\n",
    "    Wtilde = metrics.normalize_factors(factors['PW'], factors['H'])[0]\n",
    "    res['W']['fro'] = metrics.match_l2(data['W'], What, match_rows=False)['score']\n",
    "    res['W']['corr'] = metrics.match_correlation(data['W'], What, match_rows=False)['score']\n",
    "    res['H']['fro'] = metrics.match_l2(data['H'], Hhat, match_rows=True)['score']\n",
    "    res['H']['corr'] = metrics.match_correlation(data['H'], Hhat, match_rows=True)['score']\n",
    "    res['PW']['fro'] = metrics.match_l2(data['PW'], Wtilde, match_rows=False)['score']\n",
    "    res['PW']['corr'] = metrics.match_correlation(data['PW'], Wtilde, match_rows=False)['score']\n",
    "    \n",
    "    # reconstruction error\n",
    "    res['X']['uncompressed'] = metrics.error(\n",
    "        data['X'], np.dot(*mf.nmf(data['X'], rank, random_state=random)))\n",
    "    res['X']['compressed'] = metrics.error(data['X'], np.dot(What, Hhat))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_sparsity = 100\n",
      "rank = 10\n",
      "n = 2000\n",
      "m = 2000\n",
      "d = 400\n",
      "P_sparsity = 5\n",
      "nonneg = True\n",
      "noise_scale = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 342/1000 [00:00<00:00, 1704.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank 10 NMF of matrix of shape (400, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1691.40it/s]\n",
      " 20%|██        | 2/10 [00:00<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving 10 sparse recovery instances of dimension 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'W': {'fro': 0.049148860902445593, 'corr': 0.9991041959605538},\n",
       "             'H': {'fro': 0.022943871061640028, 'corr': 0.9994026481422557},\n",
       "             'PW': {'fro': 0.022912487975926033, 'corr': 0.9997903942427104},\n",
       "             'X': {'uncompressed': 0.099175327, 'compressed': 0.10979814}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_nmf_experiment(d=400, verbose=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_spca_experiment(alpha=0.1, rank=10, random_state=None, verbose=False, show_progress=False, **kwargs):\n",
    "    random = _get_random_state(random_state)\n",
    "    \n",
    "    # generate synthetic low-rank + noise matrix\n",
    "    data = generate_synthetic(rank=rank, nonneg=False, random_state=random, verbose=verbose, **kwargs)\n",
    "    \n",
    "    # factorize and recover\n",
    "    factors = mf.compressed_factorization(\n",
    "        data['PX'],\n",
    "        rank=rank,\n",
    "        fn=mf.sparse_pca,\n",
    "        alpha=alpha,\n",
    "        proj=data['P'],\n",
    "        random_state=random,\n",
    "        show_progress=show_progress,\n",
    "        verbose=verbose)\n",
    "    \n",
    "    res = defaultdict(dict)\n",
    "    \n",
    "    # factor matching\n",
    "    What, Hhat = metrics.normalize_factors(factors['W'], factors['H'])\n",
    "    Wtilde = metrics.normalize_factors(factors['PW'], factors['H'])[0]\n",
    "    res['W']['fro'] = metrics.match_l2(data['W'], What, match_rows=False)['score']\n",
    "    res['W']['corr'] = metrics.match_correlation(data['W'], What, match_rows=False)['score']\n",
    "    res['H']['fro'] = metrics.match_l2(data['H'], Hhat, match_rows=True)['score']\n",
    "    res['H']['corr'] = metrics.match_correlation(data['H'], Hhat, match_rows=True)['score']\n",
    "    res['PW']['fro'] = metrics.match_l2(data['PW'], Wtilde, match_rows=False)['score']\n",
    "    res['PW']['corr'] = metrics.match_correlation(data['PW'], Wtilde, match_rows=False)['score']\n",
    "    \n",
    "    # reconstruction error\n",
    "    res['X']['uncompressed'] = metrics.error(\n",
    "        data['X'], np.dot(*mf.sparse_pca(data['X'], rank, alpha, random_state=random)))\n",
    "    res['X']['compressed'] = metrics.error(data['X'], np.dot(What, Hhat))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_sparsity = 100\n",
      "rank = 10\n",
      "n = 2000\n",
      "m = 2000\n",
      "d = 400\n",
      "P_sparsity = 5\n",
      "nonneg = False\n",
      "noise_scale = 0.1\n",
      "Computing rank 10 sparse PCA of matrix of shape (400, 2000) with L1 parameter 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:01,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving 10 sparse recovery instances of dimension 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'W': {'fro': 0.26148362665759389, 'corr': 0.9741499153332656},\n",
       "             'H': {'fro': 0.041768433590831398, 'corr': 0.9991275702322824},\n",
       "             'PW': {'fro': 0.087209960319630186, 'corr': 0.9978464818690478},\n",
       "             'X': {'uncompressed': 0.13998630533221196,\n",
       "              'compressed': 0.27979464042601676}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_spca_experiment(d=400, alpha=0.1, verbose=True, show_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
